Many classical statistical and machine learning approaches exist that try to separate noise from speech signal. Clean speech signal without noise is vital for automatic speech recognition (ASR) systems, as it enhances performance leading to better predictions. Such denoising methods are Wiener filtering, minimum mean square error (MMSE) or kernel methods[1]. In this paper we are focusing on using the Deep Neural Network (DNN) to denoise a speech signal.

Our underlying problem is to use custom noisy dataset in Finnish language and denoise it. The dataset has the clean data for evaluation and two sets of noise with *0db* and *8db*. One approach to solve this problem is proposed in *"Speech Enhancement Based on Deep Denoising Autoencoder"* paper by Lu, Xugang, et al[1]. They propose to use deep network as it efficiently learns statistical information from the dataset. The peculiarity of their approach is the use of deep autoencoder (DAE) for noise reduction. They train the DAE by inputting noisy speech and expecting a clean output. In that way the model is supposed explicitly learns the statistical difference between clean and noisy speech[1]. As they show in their work their model does perform well, but what we are interested in is to use their model for our dataset and push the boundaries with extra experimentation.

One such experiment that we want to conduct is to train a model on clean speech (input clean speech and output the same clean speech), use that model as a base for deep auto encoder and further train it to denoise a noisy speech. The logic behind this approach is that the base model will have initial weights that we can fine-tune for denoising task.

Another experiment that we want to do is during training we randomly sample from both clean and noisy data and input it to the model and compare the results to the previously mentioned approach.

> 1. Lu, Xugang, et al. Speech Enhancement Based on Deep Denoising Autoencoder. 2013, www.isca-speech.org/archive/archive_papers/interspeech_2013/i13_0436.pdf.
